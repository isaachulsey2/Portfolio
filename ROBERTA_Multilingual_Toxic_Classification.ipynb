{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ROBERTA to achieve 93% + accuracy in toxic comment classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective:\n",
    "- Explore the exciting advantages in NLP that Google's ROBERTA model has over traditional NLP algorithms such as RNN and LSTM.\n",
    "- Utilize TPUs to speed up lengthy calculations in tensorflow.\n",
    "- Create albumentations in the training data to help the training data differentiate between \"toxic\" and \"nontoxic\" comments.\n",
    "- Process the data to be utilized by ROBERTA\n",
    "- Train the data once with the training data while using the validation dataset to make sure the model is able to generalize\n",
    "- Train the data a second time on the validation dataset to help the model learn better on other languages outside of English (the validation and testing dataframes have multilingual comments).\n",
    "- Submit predictions from the testing data into kaggle to see what Accuracy is achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "0ed28007-0ab7-4571-b60e-7831972de484",
    "_uuid": "a2c2c206-0ceb-4e72-896f-47c4acb7bc8f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from kaggle_datasets import KaggleDatasets\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import transformers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU,SimpleRNN\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from plotly import graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from nltk import sent_tokenize\n",
    "from albumentations.core.transforms_interface import DualTransform, BasicTransform\n",
    "\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import albumentations\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Loading the data from kaggle directories into Pandas Dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "e493eff6-7c98-449b-a7be-531b6be704ca",
    "_uuid": "8abdbe8a-ec19-4777-bb84-cbb0fcfeb950"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv')\n",
    "valid = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/validation.csv')\n",
    "test = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/test.csv')\n",
    "sub = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Creating strategy to utilize tensorflow's TPUs to speed up calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "8bda87fc-9df3-454e-be52-918deeeb1706",
    "_uuid": "9e22c30a-f26d-451f-b540-e1964ad74e5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  grpc://10.0.0.2:8470\n",
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    \n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These categories aren't seen in the validation or testing data. Because of this, I'm assuming that these would be classified as \"Toxic\" in the other data. To compensate for this, I am merging the values into simply the \"Toxic\" feature and dropping them to maintain the binary classification structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "8f653ded-119f-429a-aa4c-e6653291cd97",
    "_uuid": "bf060e51-5d57-4715-b9c6-85503123f34f"
   },
   "outputs": [],
   "source": [
    "#merging values for binary classification\n",
    "glue = ['severe_toxic','obscene','threat','insult','identity_hate']\n",
    "for i in glue:\n",
    "    train['toxic'] = np.where(train['toxic'] == 0, train[f'{i}'], train['toxic'])\n",
    "\n",
    "train.drop(['severe_toxic','obscene','threat','insult','identity_hate'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Below, I'm doing a number of operations to try to make the training data more like the validation and testing data. Further, I'm also implementing albumentations into the training data in an effort to help the model better differentiate between toxic and nontoxic text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLPTransform(BasicTransform):\n",
    "    \"\"\" Transform for nlp task.\"\"\"\n",
    "    LANGS = {\n",
    "        'en': 'english',\n",
    "        'it': 'italian', \n",
    "        'fr': 'french', \n",
    "        'es': 'spanish',\n",
    "        'tr': 'turkish', \n",
    "        'ru': 'russian',\n",
    "        'pt': 'portuguese'\n",
    "    }\n",
    "\n",
    "    @property\n",
    "    def targets(self):\n",
    "        return {\"data\": self.apply}\n",
    "    \n",
    "    def update_params(self, params, **kwargs):\n",
    "        if hasattr(self, \"interpolation\"):\n",
    "            params[\"interpolation\"] = self.interpolation\n",
    "        if hasattr(self, \"fill_value\"):\n",
    "            params[\"fill_value\"] = self.fill_value\n",
    "        return params\n",
    "\n",
    "    def get_sentences(self, text, lang='en'):\n",
    "        return sent_tokenize(text, self.LANGS.get(lang, 'english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShuffleSentencesTransform(NLPTransform):\n",
    "    \"\"\" Do shuffle by sentence \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(ShuffleSentencesTransform, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        sentences = self.get_sentences(text, lang)\n",
    "        random.shuffle(sentences)\n",
    "        return ' '.join(sentences), lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExcludeDuplicateSentencesTransform(NLPTransform):\n",
    "    \"\"\" Exclude equal sentences \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(ExcludeDuplicateSentencesTransform, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        sentences = []\n",
    "        for sentence in self.get_sentences(text, lang):\n",
    "            sentence = sentence.strip()\n",
    "            if sentence not in sentences:\n",
    "                sentences.append(sentence)\n",
    "        return ' '.join(sentences), lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExcludeNumbersTransform(NLPTransform):\n",
    "    \"\"\" exclude any numbers \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(ExcludeNumbersTransform, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        text = re.sub(r'[0-9]', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text, lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExcludeHashtagsTransform(NLPTransform):\n",
    "    \"\"\" Exclude any hashtags with # \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(ExcludeHashtagsTransform, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        text = re.sub(r'#[\\S]+\\b', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text, lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExcludeUsersMentionedTransform(NLPTransform):\n",
    "    \"\"\" Exclude @users \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(ExcludeUsersMentionedTransform, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        text = re.sub(r'@[\\S]+\\b', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text, lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExcludeUrlsTransform(NLPTransform):\n",
    "    \"\"\" Exclude urls \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(ExcludeUrlsTransform, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        text = re.sub(r'https?\\S+', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text, lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwapWordsTransform(NLPTransform):\n",
    "    \"\"\" Swap words next to each other \"\"\"\n",
    "    def __init__(self, swap_distance=1, swap_probability=0.1, always_apply=False, p=0.5):\n",
    "        \"\"\"  \n",
    "        swap_distance - distance for swapping words\n",
    "        swap_probability - probability of swapping for one word\n",
    "        \"\"\"\n",
    "        super(SwapWordsTransform, self).__init__(always_apply, p)\n",
    "        self.swap_distance = swap_distance\n",
    "        self.swap_probability = swap_probability\n",
    "        self.swap_range_list = list(range(1, swap_distance+1))\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        words = text.split()\n",
    "        words_count = len(words)\n",
    "        if words_count <= 1:\n",
    "            return text, lang\n",
    "\n",
    "        new_words = {}\n",
    "        for i in range(words_count):\n",
    "            if random.random() > self.swap_probability:\n",
    "                new_words[i] = words[i]\n",
    "                continue\n",
    "    \n",
    "            if i < self.swap_distance:\n",
    "                new_words[i] = words[i]\n",
    "                continue\n",
    "    \n",
    "            swap_idx = i - random.choice(self.swap_range_list)\n",
    "            new_words[i] = new_words[swap_idx]\n",
    "            new_words[swap_idx] = words[i]\n",
    "\n",
    "        return ' '.join([v for k, v in sorted(new_words.items(), key=lambda x: x[0])]), lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CutOutWordsTransform(NLPTransform):\n",
    "    \"\"\" Remove random words \"\"\"\n",
    "    def __init__(self, cutout_probability=0.05, always_apply=False, p=0.5):\n",
    "        super(CutOutWordsTransform, self).__init__(always_apply, p)\n",
    "        self.cutout_probability = cutout_probability\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        words = text.split()\n",
    "        words_count = len(words)\n",
    "        if words_count <= 1:\n",
    "            return text, lang\n",
    "        \n",
    "        new_words = []\n",
    "        for i in range(words_count):\n",
    "            if random.random() < self.cutout_probability:\n",
    "                continue\n",
    "            new_words.append(words[i])\n",
    "\n",
    "        if len(new_words) == 0:\n",
    "            return words[random.randint(0, words_count-1)], lang\n",
    "\n",
    "        return ' '.join(new_words), lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNonToxicSentencesTransform(NLPTransform):\n",
    "    \"\"\" Add random non toxic statement \"\"\"\n",
    "    def __init__(self, non_toxic_sentences, sentence_range=(1, 3), always_apply=False, p=0.5):\n",
    "        super(AddNonToxicSentencesTransform, self).__init__(always_apply, p)\n",
    "        self.sentence_range = sentence_range\n",
    "        self.non_toxic_sentences = non_toxic_sentences\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "\n",
    "        sentences = self.get_sentences(text, lang)\n",
    "        for i in range(random.randint(*self.sentence_range)):\n",
    "            sentences.append(random.choice(self.non_toxic_sentences))\n",
    "        \n",
    "        random.shuffle(sentences)\n",
    "        return ' '.join(sentences), lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    return albumentations.Compose([\n",
    "        ExcludeDuplicateSentencesTransform(p=0.9),  # here not p=1.0 because your nets should get some difficulties\n",
    "        albumentations.OneOf([\n",
    "            AddNonToxicSentencesTransform(non_toxic_sentences=list(non_toxic_sentences), p=0.8, sentence_range=(1,3)),\n",
    "            ShuffleSentencesTransform(p=0.8),\n",
    "        ]),\n",
    "        ExcludeNumbersTransform(p=0.8),\n",
    "        ExcludeHashtagsTransform(p=0.5),\n",
    "        ExcludeUsersMentionedTransform(p=0.9),\n",
    "        ExcludeUrlsTransform(p=0.9),\n",
    "        CutOutWordsTransform(p=0.1),\n",
    "        SwapWordsTransform(p=0.1),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetRetriever(Dataset):\n",
    "\n",
    "    def __init__(self, df, train_transforms=None):\n",
    "        self.comment_texts = df['comment_text'].values\n",
    "        self.langs = df['lang'].values\n",
    "        self.train_transforms = train_transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.comment_texts.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.comment_texts[idx]\n",
    "        lang = self.langs[idx]\n",
    "        if self.train_transforms:\n",
    "            text, _ = self.train_transforms(data=(text, lang))['data']\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 895/895 [00:00<00:00, 3180.00it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp_transform = NLPTransform()\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv', nrows= 1000)\n",
    "df = df[df.toxic == 0]\n",
    "df['lang'] = 'en'\n",
    "non_toxic_sentences = set()\n",
    "for comment_text in tqdm(df['comment_text'], total=df.shape[0]):\n",
    "    non_toxic_sentences.update(nlp_transform.get_sentences(comment_text), 'en')\n",
    "\n",
    "transform = AddNonToxicSentencesTransform(non_toxic_sentences=list(non_toxic_sentences), p=1.0, sentence_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 895/895 [00:00<00:00, 1002.84it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = DatasetRetriever(df, train_transforms=get_train_transforms())\n",
    "for albumentation_text in tqdm(dataset, total=len(dataset)):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['severe_toxic','obscene','threat','insult','identity_hate'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [train, df]\n",
    "train = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2321"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['comment_text'].apply(lambda x:len(str(x).split())).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a helper function for AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc(predictions,target):\n",
    "    '''\n",
    "    This methods returns the AUC Score when given the Predictions\n",
    "    and Labels\n",
    "    '''\n",
    "    \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(target, predictions)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Splitting the data in an 80-20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xvalid, ytrain, yvalid = train_test_split(train.comment_text.values, train.toxic.values, \n",
    "                                                  stratify=train.toxic.values, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Calling and defining attributes for the neural network and the final encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Configuration\n",
    "EPOCHS = 4\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "MAX_LEN = 192\n",
    "MODEL = 'jplu/tf-xlm-roberta-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022d7ec0c3c942c69d2f12aafc973c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=513.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89a11d85b7ee4ca09eb8fe5e144ddc5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Creating an encoding function to make the data usable in ROBERTA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regular_encode(texts, tokenizer, maxlen=512):\n",
    "    enc_di = tokenizer.batch_encode_plus(\n",
    "        texts, \n",
    "        return_attention_masks=False, \n",
    "        return_token_type_ids=False,\n",
    "        pad_to_max_length=True,\n",
    "        max_length=maxlen\n",
    "    )\n",
    "    \n",
    "    return np.array(enc_di['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Encoding the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = regular_encode(train.comment_text.values, tokenizer, maxlen=MAX_LEN)\n",
    "x_valid = regular_encode(valid.comment_text.values, tokenizer, maxlen=MAX_LEN)\n",
    "x_test = regular_encode(test.content.values, tokenizer, maxlen=MAX_LEN)\n",
    "\n",
    "y_train = train.toxic.values\n",
    "y_valid = valid.toxic.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Making skeleton model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(transformer, loss = 'binary_crossentropy',  max_len=512):\n",
    "    \"\"\"\n",
    "    function for training the BERT model\n",
    "    \"\"\"\n",
    "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    sequence_output = transformer(input_word_ids)[0]\n",
    "    cls_token = sequence_output[:, 0, :]\n",
    "    out = Dense(1, activation='sigmoid')(cls_token)\n",
    "    \n",
    "    model = Model(inputs=input_word_ids, outputs=out)\n",
    "    \n",
    "    \n",
    "    model.compile(Adam(lr=1e-6), loss= loss, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizing a loss function designed by researches from Facebook to be optimal for binary classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def focal_loss(gamma=2., alpha=.2):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final transform for utilization of data into ROBERTA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((x_train, y_train))\n",
    "    .repeat()\n",
    "    .shuffle(2048)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "valid_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((x_valid, y_valid))\n",
    "    .batch(BATCH_SIZE)\n",
    "    .cache()\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "test_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(x_test)\n",
    "    .batch(BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading ROBERTA to utilize TPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f93902db3f45f2bf91d434aa02292b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=3271420488.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_word_ids (InputLayer)  [(None, 192)]             0         \n",
      "_________________________________________________________________\n",
      "tf_roberta_model (TFRobertaM ((None, 192, 1024), (None 559890432 \n",
      "_________________________________________________________________\n",
      "tf_op_layer_strided_slice (T [(None, 1024)]            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 559,891,457\n",
      "Trainable params: 559,891,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "CPU times: user 2min 5s, sys: 39.7 s, total: 2min 44s\n",
      "Wall time: 2min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with strategy.scope():\n",
    "    transformer_layer = TFAutoModel.from_pretrained(MODEL)\n",
    "    model = build_model(transformer_layer,loss=focal_loss(gamma=1.5), max_len=MAX_LEN)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using learning rate scheduler for dynamic learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lrfn(lr_start=0.000001, lr_max=0.000002, \n",
    "               lr_min=0.0000001, lr_rampup_epochs=7, \n",
    "               lr_sustain_epochs=0, lr_exp_decay=.87):\n",
    "    lr_max = lr_max * strategy.num_replicas_in_sync\n",
    "\n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_rampup_epochs:\n",
    "            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n",
    "        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n",
    "            lr = lr_max\n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n",
    "        return lr\n",
    "    \n",
    "    return lrfn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the data on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-06.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 256002048 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1753/1753 [==============================] - 775s 442ms/step - accuracy: 0.9033 - loss: 0.0353 - val_accuracy: 0.8530 - val_loss: 0.0486 - lr: 1.0000e-06\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 3.142857142857143e-06.\n",
      "Epoch 2/5\n",
      "1753/1753 [==============================] - 741s 423ms/step - accuracy: 0.9478 - loss: 0.0147 - val_accuracy: 0.8591 - val_loss: 0.0456 - lr: 3.1429e-06\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 5.285714285714285e-06.\n",
      "Epoch 3/5\n",
      "1753/1753 [==============================] - 741s 423ms/step - accuracy: 0.9550 - loss: 0.0123 - val_accuracy: 0.8584 - val_loss: 0.0507 - lr: 5.2857e-06\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 7.4285714285714275e-06.\n",
      "Epoch 4/5\n",
      "1753/1753 [==============================] - 742s 423ms/step - accuracy: 0.9562 - loss: 0.0117 - val_accuracy: 0.8638 - val_loss: 0.0391 - lr: 7.4286e-06\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 9.571428571428572e-06.\n",
      "Epoch 5/5\n",
      "1753/1753 [==============================] - 742s 423ms/step - accuracy: 0.9585 - loss: 0.0108 - val_accuracy: 0.8625 - val_loss: 0.0428 - lr: 9.5714e-06\n"
     ]
    }
   ],
   "source": [
    "lrfn = build_lrfn()\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\n",
    "\n",
    "\n",
    "n_steps = x_train.shape[0] // BATCH_SIZE\n",
    "train_history = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch= n_steps,\n",
    "    validation_data=valid_dataset,\n",
    "    callbacks=[lr_schedule],\n",
    "    epochs= 5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the data on the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-06.\n",
      "Epoch 1/5\n",
      "62/62 [==============================] - 25s 411ms/step - accuracy: 0.8681 - loss: 0.0342 - lr: 1.0000e-06\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 3.142857142857143e-06.\n",
      "Epoch 2/5\n",
      "62/62 [==============================] - 26s 411ms/step - accuracy: 0.8830 - loss: 0.0272 - lr: 3.1429e-06\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 5.285714285714285e-06.\n",
      "Epoch 3/5\n",
      "62/62 [==============================] - 25s 408ms/step - accuracy: 0.9018 - loss: 0.0243 - lr: 5.2857e-06\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 7.4285714285714275e-06.\n",
      "Epoch 4/5\n",
      "62/62 [==============================] - 25s 408ms/step - accuracy: 0.9201 - loss: 0.0201 - lr: 7.4286e-06\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 9.571428571428572e-06.\n",
      "Epoch 5/5\n",
      "62/62 [==============================] - 25s 409ms/step - accuracy: 0.9315 - loss: 0.0171 - lr: 9.5714e-06\n"
     ]
    }
   ],
   "source": [
    "n_steps = x_valid.shape[0] // BATCH_SIZE\n",
    "train_history_2 = model.fit(\n",
    "    valid_dataset.repeat(),\n",
    "    steps_per_epoch=n_steps,\n",
    "    callbacks=[lr_schedule],\n",
    "    epochs= 5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Creating predictions and writing them to CSV to test final accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499/499 [==============================] - 63s 126ms/step\n"
     ]
    }
   ],
   "source": [
    "sub['toxic'] = model.predict(test_dataset, verbose=1)\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I scored 93.23% accuracy on the testing data. If you want to check me, you can look [here](https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification/leaderboard). This is an astonishingly good result for my first delve into NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I entered this kaggle competition as a way to explore new extensions of machine learning into NLP. I was pleasantly surprised at the high level of accuracy that can be achieved utilizing transfer learning from Google's ROBERTA and applying the concept of albumentations from computer vision to NLP. I am excited to see where this field goes moving forward and hope to be able to contribute to its evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "022d7ec0c3c942c69d2f12aafc973c5f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_449c2bda77bc4452aff60acc3f1143c9",
        "IPY_MODEL_df852eac54cd479f840b757cb515797f"
       ],
       "layout": "IPY_MODEL_be07fc0a969749bdbb32e5e5016c0227"
      }
     },
     "064908c73b1d4cc195d38d814d689ace": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "0b5f65924d0c479aa6363a80eacc961c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "268f14778d194606979aa2e2fc31ea99": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "3eabf0c6c23240f9b28fd92a8da94d6e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "41de498d4d3d48fab9b81f7a86036baf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "449c2bda77bc4452aff60acc3f1143c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f2efe785191545b08bb521992f1bdd0f",
       "max": 513,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_064908c73b1d4cc195d38d814d689ace",
       "value": 513
      }
     },
     "478f8476083947ac9f62b3a036b91e8a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "66a68bdc564e49cebe6bb6b396056a4d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_41de498d4d3d48fab9b81f7a86036baf",
       "max": 3271420488,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_268f14778d194606979aa2e2fc31ea99",
       "value": 3271420488
      }
     },
     "68e16a82f1804c11b2480953cac75e07": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "68f93902db3f45f2bf91d434aa02292b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_66a68bdc564e49cebe6bb6b396056a4d",
        "IPY_MODEL_be18e03edf9141a28719a536d41669fd"
       ],
       "layout": "IPY_MODEL_478f8476083947ac9f62b3a036b91e8a"
      }
     },
     "75e619d614df4dc4a6577c71b804d3b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "80a6e0d59f694e2f9135da85db2dab47": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "89a11d85b7ee4ca09eb8fe5e144ddc5e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f8c3fd20fd3a4d0dae8f461bd6ad5f99",
        "IPY_MODEL_b294366fd3b44f0fb0efa49de9295605"
       ],
       "layout": "IPY_MODEL_80a6e0d59f694e2f9135da85db2dab47"
      }
     },
     "9379db582c38421eae280218631d51b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "b084424d41dd4aa29fdd4ef5ac16422c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b294366fd3b44f0fb0efa49de9295605": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0b5f65924d0c479aa6363a80eacc961c",
       "placeholder": "​",
       "style": "IPY_MODEL_75e619d614df4dc4a6577c71b804d3b8",
       "value": " 5.07M/5.07M [00:03&lt;00:00, 1.63MB/s]"
      }
     },
     "be07fc0a969749bdbb32e5e5016c0227": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "be18e03edf9141a28719a536d41669fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fdb01ef8793f4634ade829ce9c622e3d",
       "placeholder": "​",
       "style": "IPY_MODEL_e07113502dd040ebb499478ff0fbf94b",
       "value": " 3.27G/3.27G [01:41&lt;00:00, 32.2MB/s]"
      }
     },
     "df852eac54cd479f840b757cb515797f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3eabf0c6c23240f9b28fd92a8da94d6e",
       "placeholder": "​",
       "style": "IPY_MODEL_68e16a82f1804c11b2480953cac75e07",
       "value": " 513/513 [00:00&lt;00:00, 2.17kB/s]"
      }
     },
     "e07113502dd040ebb499478ff0fbf94b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f2efe785191545b08bb521992f1bdd0f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f8c3fd20fd3a4d0dae8f461bd6ad5f99": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b084424d41dd4aa29fdd4ef5ac16422c",
       "max": 5069051,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9379db582c38421eae280218631d51b1",
       "value": 5069051
      }
     },
     "fdb01ef8793f4634ade829ce9c622e3d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
